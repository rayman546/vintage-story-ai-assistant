# Vintage Story AI Assistant

A local, offline-first AI assistant for the game Vintage Story, built with Tauri, Rust, and React.

## Features

- **Offline-first**: All AI processing happens locally
- **Vintage Story specific**: Built-in knowledge from the official wiki
- **Cross-platform**: Runs on Windows, macOS, and Linux
- **Local LLM**: Uses Ollama for AI inference
- **RAG System**: Retrieval-Augmented Generation for accurate responses

## Development Setup

### Prerequisites

- Rust (1.85.0+)
- Node.js (18+)
- Tauri CLI (installed automatically)

### Installation

1. Clone this repository
2. Install frontend dependencies:
   ```bash
   npm install
   ```
3. Install Rust dependencies:
   ```bash
   cd src-tauri
   cargo build
   ```

### Running in Development

```bash
# Start the development server
npm run tauri dev
```

### Building for Production

```bash
# Build the application
npm run tauri build
```

## Project Structure

```
vintage-story-ai-assistant/
â”œâ”€â”€ src/                    # React frontend
â”‚   â”œâ”€â”€ App.tsx            # Main application component
â”‚   â”œâ”€â”€ main.tsx           # React entry point
â”‚   â””â”€â”€ styles.css         # Global styles
â”œâ”€â”€ src-tauri/             # Rust backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ commands/      # Tauri commands (API endpoints)
â”‚   â”‚   â”œâ”€â”€ services/      # Core business logic
â”‚   â”‚   â”œâ”€â”€ config.rs      # Configuration management
â”‚   â”‚   â”œâ”€â”€ errors.rs      # Error handling
â”‚   â”‚   â””â”€â”€ main.rs        # Application entry point
â”‚   â”œâ”€â”€ Cargo.toml         # Rust dependencies
â”‚   â”œâ”€â”€ tauri.conf.json    # Tauri configuration
â”‚   â””â”€â”€ build.rs           # Build script
â”œâ”€â”€ package.json           # Frontend dependencies
â”œâ”€â”€ vite.config.ts         # Vite configuration
â””â”€â”€ tailwind.config.js     # Tailwind CSS configuration
```

## Implementation Status

### âœ… Completed
- Basic Tauri project structure
- Frontend chat interface
- Ollama service integration (basic)
- Command structure for frontend-backend communication

### ðŸš§ In Progress
- Wiki scraping and processing
- Vector database integration (sled)
- Embedding service implementation
- RAG pipeline

### ðŸ“‹ Planned
- Model download interface
- Wiki content management
- Advanced chat features
- Cross-platform packaging
- Auto-updater

## Technical Stack

- **Frontend**: React 18 + TypeScript + Tailwind CSS
- **Backend**: Rust + Tauri
- **LLM Engine**: Ollama
- **Vector Database**: sled (embedded key-value store)
- **Build Tool**: Vite
- **Package Manager**: npm

## Technology Decisions

### Vector Database: sled vs LanceDB

**Decision**: Using sled as the embedded vector database.

**Rationale**:
- **Existing Implementation**: sled is already integrated and functional in the codebase with working vector storage operations
- **Stability Focus**: During the critical fixes phase, maintaining existing working components reduces risk
- **Simplicity**: sled provides sufficient embedded key-value storage for the current RAG system requirements
- **Dependency Management**: Keeps the dependency footprint smaller and build process simpler
- **Future Flexibility**: The vector database interface is abstracted, allowing for future migration to LanceDB if advanced vector operations become necessary

## Contributing

This project is in early development. Contributions are welcome!

## License

MIT License - see LICENSE file for details.
