# Product Overview

## Vintage Story AI Assistant

A local, offline-first AI assistant specifically designed for the game Vintage Story. The application provides intelligent assistance for gameplay, crafting, mechanics, and general game knowledge through a desktop application.

## Key Features

- **Offline-first**: All AI processing happens locally using Ollama
- **Game-specific knowledge**: Built-in knowledge from the official Vintage Story wiki
- **Cross-platform**: Runs on Windows, macOS, and Linux
- **RAG System**: Retrieval-Augmented Generation for accurate, context-aware responses
- **Local LLM**: Uses Ollama for AI inference without external dependencies

## Target Users

Players of Vintage Story who want quick, accurate answers about game mechanics, crafting recipes, survival strategies, and gameplay tips without leaving the game or searching through wikis manually.

## Current Status

Early development phase with basic chat interface, Ollama integration, and wiki scraping capabilities. The RAG pipeline and vector database integration are in progress.